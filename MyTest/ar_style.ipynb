{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"TF Hub version: \", hub.__version__)\n",
    "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
    "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define image loading and visualization functions  { display-mode: \"form\" }\n",
    "\n",
    "def crop_center(image):\n",
    "  \"\"\"Returns a cropped square image.\"\"\"\n",
    "  shape = image.shape\n",
    "  new_shape = min(shape[1], shape[2])\n",
    "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
    "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
    "  image = tf.image.crop_to_bounding_box(\n",
    "      image, offset_y, offset_x, new_shape, new_shape)\n",
    "  return image\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img = tf.io.decode_image(\n",
    "      tf.io.read_file(image_path),\n",
    "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
    "  img = crop_center(img)\n",
    "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
    "  return img\n",
    "\n",
    "def load_image_local(image_path, image_size=(256, 256), preserve_aspect_ratio=True): #modified this one to load files from local\n",
    "  \"\"\"Loads and preprocesses images.\"\"\"\n",
    "  # Cache image file locally.\n",
    "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
    "  img = tf.io.decode_image(\n",
    "      tf.io.read_file(image_path),\n",
    "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
    "  img = crop_center(img)\n",
    "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
    "  return img\n",
    "\n",
    "def show_n(images, titles=('',)):\n",
    "  n = len(images)\n",
    "  image_sizes = [image.shape[1] for image in images]\n",
    "  w = (image_sizes[0] * 6) // 320\n",
    "  plt.figure(figsize=(w * n, w))\n",
    "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
    "  for i in range(n):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.imshow(images[i][0], aspect='equal')\n",
    "    plt.axis('off')\n",
    "    plt.title(titles[i] if len(titles) > i else '')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load example images  { display-mode: \"form\" }\n",
    "\n",
    "content_image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Golden_Gate_Bridge_from_Battery_Spencer.jpg/640px-Golden_Gate_Bridge_from_Battery_Spencer.jpg'  # @param {type:\"string\"}\n",
    "style_image_url = 'https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg'  # @param {type:\"string\"}\n",
    "output_image_size = 384  # @param {type:\"integer\"}\n",
    "\n",
    "# The content image size can be arbitrary.\n",
    "content_img_size = (output_image_size, output_image_size)\n",
    "# The style prediction model was trained with image size 256 and it's the \n",
    "# recommended image size for the style image (though, other sizes work as \n",
    "# well but will lead to different results).\n",
    "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
    "\n",
    "content_image = load_image(content_image_url, content_img_size)\n",
    "style_image = load_image(style_image_url, style_img_size)\n",
    "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[5,5], padding='SAME')\n",
    "show_n([content_image, style_image], ['Content image', 'Style image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @load images from local\n",
    "\n",
    "output_image_size = 384  # @param {type:\"integer\"}\n",
    "\n",
    "# The content image size can be arbitrary.\n",
    "content_img_size = (output_image_size, output_image_size)\n",
    "# The style prediction model was trained with image size 256 and it's the \n",
    "# recommended image size for the style image (though, other sizes work as \n",
    "# well but will lead to different results).\n",
    "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
    "content_image_local_path = r\"C:\\Users\\DanielPc\\Desktop\\stylesAndPictures\\comic_style.jpg\"\n",
    "style_image_local_path = r\"C:\\Users\\DanielPc\\Desktop\\stylesAndPictures\\boat.jpeg\"\n",
    "\n",
    "content_image = load_image_local(content_image_local_path, content_img_size)\n",
    "style_image = load_image_local(style_image_local_path, style_img_size)\n",
    "style_image = tf.nn.avg_pool(style_image, ksize=[2,2], strides=[2,2], padding='SAME')\n",
    "show_n([content_image, style_image], ['Content image', 'Style image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF Hub module.\n",
    "\n",
    "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
    "hub_module = hub.load(hub_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = hub_module(content_image, style_image)\n",
    "stylized_image = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylize content image with given style image.\n",
    "# This is pretty fast within a few milliseconds on a GPU.\n",
    "\n",
    "outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
    "stylized_image = outputs[0]\n",
    "\n",
    "# Visualize input images and the generated stylized image.\n",
    "show_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f42ff56e0420f2e92da8b5a96da257336cb9821da63c2f220ab0c7324db6447a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
